# -*- coding: utf-8 -*-
"""Phase2_task0b.ipynb

Automatically generated by Colaboratory.
Author: Amey Athale

Original file is located at
    https://colab.research.google.com/drive/1pdYyWBQFOAWsmqBL0-gxjY4CWNT7lxHa
"""

import glob
import json
import os
from timeit import timeit

import numpy as np
import pandas as pd

from main import phase2_EDIT_Dist as edit_distance
from main import phase2_DTW as dtw


def similarity_matrix(option, sim_mat=None):

    if option == '1':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '2':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '3':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '4':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '5':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '6':
        sim_mat = find_edit_dist_sim_matrix()
    elif option == '7':
        sim_mat = find_dtw_sim_matrix()

    # perform SVD on this gesture-gesture similarity matrix


@timeit
def find_dtw_sim_matrix():
    data_dir = 'data'

    file_names = glob.glob("./" + data_dir + "/*.wrd")
    file_names.sort()
    for i in range(len(file_names)):
        file_names[i] = os.path.splitext(os.path.basename(file_names[i]))[0]

    df = pd.DataFrame(0.0, index=file_names, columns=file_names)

    for i in range(len(file_names)):
        for j in range(i, len(file_names)):
            f1 = json.load(open('./' + data_dir + '/' + file_names[i] + '.wrd'))
            f2 = json.load(open('./' + data_dir + '/' + file_names[j] + '.wrd'))
            comp = list(f1.keys())

            temp = []
            for c in comp:
                for senid in f1[c]:
                    w1 = list(np.array(f1[c][str(senid)]['words'])[:, 0])
                    w1_c = list(np.array(f1[c][str(senid)]['words'])[:, 1])
                    w2 = list(np.array(f2[c][str(senid)]['words'])[:, 0])
                    w2_c = list(np.array(f2[c][str(senid)]['words'])[:, 1])
                    dtw_val = dtw.dtw(w1, w2, w1_c, w2_c)
                    temp.append(1 / (1 + dtw_val))

            f1 = file_names[i]
            f2 = file_names[j]

            average = np.average(temp)

            df[f1][f2] = average
            df[f2][f1] = average

    df.to_csv('DTW_sim_matrix.csv')
    return df


# Task 3a Part 1 user option 6:
def find_edit_dist_sim_matrix():
    data_dir = 'data'
    fnames = glob.glob("./" + data_dir + "/*.wrd")
    fnames.sort()
    for i in range(len(fnames)):
        fnames[i] = os.path.splitext(os.path.basename(fnames[i]))[0]

    df = pd.DataFrame(0.0, index=fnames, columns=fnames)

    for i in range(len(fnames)):
        for j in range(i, len(fnames)):
            f1 = json.load(open('./' + data_dir + '/' + fnames[i] + '.wrd'))
            f2 = json.load(open('./' + data_dir + '/' + fnames[j] + '.wrd'))
            comp = list(f1.keys())

            temp = []
            for c in comp:
                for sensor_id in f1[c]:
                    w1 = list(np.array(f1[c][str(sensor_id)]['words'])[:, 0])
                    w2 = list(np.array(f2[c][str(sensor_id)]['words'])[:, 0])
                    temp.append(edit_distance.editdist(w1, w2))

            f1 = fnames[i]
            f2 = fnames[j]

            for k in range(len(temp)):
                temp[k] = 1 / (1 + temp[k])

            df[f1][f2] = np.average(temp)
            df[f2][f1] = np.average(temp)

    df.to_csv('task3a_Edit_Dist_sim_matrix.csv')
    # np.savetxt('task3a_UsrOpt6_sim_matrix.txt', sim_mat)
    # sim_mat = np.loadtxt('task3a_UsrOpt6_sim_matrix.txt')
    # sim_mat
    return df


if __name__ == '__main__':
    user_option = input('1. Dot product | [2,3,4,5]. [PCA,SVD,NMF,LDA] | 6. Edit dist | 7. DTW')
    print(user_option)
    similarity_matrix(user_option)
